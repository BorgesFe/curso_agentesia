{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BorgesFe/curso_agentesia/blob/main/C%C3%B3pia_de_Agente_grupo_GTIA_(vers%C3%A3o_1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtsHCG8NkmBh"
      },
      "source": [
        "**Agente GTIA**\n",
        "\n",
        "Este notebook é um trabalho do curso Agentes Autônomos com Redes Generativas - I2A2.\n",
        "\n",
        "Ele permite que você pergunte qualquer coisa sobre os dados nos arquivos CSV e o agente vai procurar diretamente a resposta neles.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalação de bibliotecas - organização do ambiente de trabalho\n",
        "!pip install -q openai pandas python-dotenv gradio\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "import io"
      ],
      "metadata": {
        "id": "wWq7OlOqrQlN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Montagem do Google Drive e leitura da chave .env\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    zip_path = \"/content/drive/MyDrive/202401--NFs.zip\"\n",
        "\n",
        "    # Leitura do arquivo .env com a chave da OpenAI\n",
        "    from dotenv import load_dotenv\n",
        "    import os\n",
        "\n",
        "    env_path = '/content/drive/MyDrive/segredos/.env'\n",
        "    load_dotenv(dotenv_path=env_path)\n",
        "\n",
        "    os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "\n",
        "\n",
        "except ImportError:\n",
        "    print(\"Google Colab drive não está disponível. Certifique-se de que o arquivo ZIP está no caminho correto para execução local.\")\n",
        "    zip_path = \"202401--NFs.zip\"\n",
        "\n",
        "extract_path = \"/content/nfs\"  # Pasta onde os CSVs serão extraídos\n",
        "\n",
        "# Garante que o diretório de extração exista\n",
        "os.makedirs(extract_path, exist_ok=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViGl40V6sFmt",
        "outputId": "a64cb5bd-1d75-49ec-8d67-cc1bb2481129"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Extração do ZIP contendo os CSVs\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(f\"Arquivos extraídos para: {extract_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Erro: Arquivo ZIP não encontrado em {zip_path}. Por favor, verifique o caminho.\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao extrair o arquivo ZIP: {e}\")\n",
        "    exit()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsbEOonmsNNZ",
        "outputId": "51267732-0e53-45d9-be0a-6fc3ddc23d6e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivos extraídos para: /content/nfs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregamento dos dados\n",
        "try:\n",
        "    cabecalho_df = pd.read_csv(f\"{extract_path}/202401_NFs_Cabecalho.csv\")\n",
        "    itens_df = pd.read_csv(f\"{extract_path}/202401_NFs_Itens.csv\")\n",
        "    print(\"Dados CSV carregados com sucesso.\")\n",
        "\n",
        "    # Mostrar informações dos dados\n",
        "    print(f\"\\nCabeçalho - {len(cabecalho_df)} registros\")\n",
        "    print(\"Colunas:\", list(cabecalho_df.columns))\n",
        "\n",
        "    print(f\"\\nItens - {len(itens_df)} registros\")\n",
        "    print(\"Colunas:\", list(itens_df.columns))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao carregar os arquivos CSV: {e}\")\n",
        "    cabecalho_df = pd.DataFrame()\n",
        "    itens_df = pd.DataFrame()\n",
        "\n",
        "def perguntar_ao_agente(pergunta):\n",
        "    \"\"\"\n",
        "    Agente que usa OpenAI para interpretar perguntas e gerar análises dos dados\n",
        "    \"\"\"\n",
        "\n",
        "    if not pergunta.strip():\n",
        "        return \"Por favor, faça uma pergunta sobre os dados das notas fiscais.\"\n",
        "\n",
        "    # Verifica se os dados foram carregados\n",
        "    if cabecalho_df.empty or itens_df.empty:\n",
        "        return \"Erro: Dados não carregados. Verifique os arquivos CSV.\"\n",
        "\n",
        "    # Cria contexto sobre os dados disponíveis\n",
        "    contexto_dados = f\"\"\"\n",
        "    DADOS DISPONÍVEIS:\n",
        "\n",
        "    1. CABEÇALHO DAS NOTAS FISCAIS ({len(cabecalho_df)} registros):\n",
        "    Colunas: {', '.join(cabecalho_df.columns)}\n",
        "\n",
        "    2. ITENS DAS NOTAS FISCAIS ({len(itens_df)} registros):\n",
        "    Colunas: {', '.join(itens_df.columns)}\n",
        "\n",
        "    PERGUNTA DO USUÁRIO: {pergunta}\n",
        "\n",
        "    Por favor, analise a pergunta e gere código Python usando pandas para respondê-la.\n",
        "    Use as variáveis 'cabecalho_df' e 'itens_df'.\n",
        "\n",
        "    IMPORTANTE:\n",
        "    - Retorne apenas o código Python executável\n",
        "    - Use try/except para tratamento de erros\n",
        "    - Armazene o resultado final em uma variável chamada 'resposta'\n",
        "    - Se for um DataFrame grande, limite a 10 registros\n",
        "    - Formate valores monetários adequadamente\n",
        "\n",
        "    Exemplo:\n",
        "    try:\n",
        "        resultado = itens_df.groupby('coluna_fornecedor')['coluna_valor'].sum()\n",
        "        maior_fornecedor = resultado.idxmax()\n",
        "        maior_valor = resultado.max()\n",
        "        resposta = f\"Maior fornecedor: {{maior_fornecedor}} com R$ {{maior_valor:,.2f}}\"\n",
        "    except Exception as e:\n",
        "        resposta = f\"Erro na análise: {{str(e)}}\"\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Chama a OpenAI para gerar o código\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[{\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"Você é um especialista em análise de dados com pandas. Gere código Python limpo e executável.\"\n",
        "            }, {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": contexto_dados\n",
        "            }],\n",
        "            temperature=0.1,\n",
        "            max_tokens=500\n",
        "        )\n",
        "\n",
        "        codigo_gerado = response.choices[0].message.content.strip()\n",
        "\n",
        "        # Remove formatação markdown se presente\n",
        "        if \"```python\" in codigo_gerado:\n",
        "            codigo_gerado = codigo_gerado.split(\"```python\")[1].split(\"```\")[0].strip()\n",
        "        elif \"```\" in codigo_gerado:\n",
        "            codigo_gerado = codigo_gerado.split(\"```\")[1].strip()\n",
        "\n",
        "        # Executa o código gerado em ambiente seguro\n",
        "        ambiente_execucao = {\n",
        "            'cabecalho_df': cabecalho_df,\n",
        "            'itens_df': itens_df,\n",
        "            'pd': pd,\n",
        "            'resposta': None\n",
        "        }\n",
        "\n",
        "        exec(codigo_gerado, {\"__builtins__\": {}}, ambiente_execucao)\n",
        "\n",
        "        resultado = ambiente_execucao.get('resposta')\n",
        "\n",
        "        if resultado is None:\n",
        "            return \"Não foi possível gerar uma resposta para sua pergunta.\"\n",
        "\n",
        "        return str(resultado)\n",
        "\n",
        "    except Exception as e:\n",
        "        # Fallback: tenta responder com lógica pré-definida\n",
        "        return responder_perguntas_comuns(pergunta)\n",
        "\n",
        "def responder_perguntas_comuns(pergunta):\n",
        "    \"\"\"\n",
        "    Fallback para perguntas comuns quando a IA falha\n",
        "    \"\"\"\n",
        "    pergunta_lower = pergunta.lower()\n",
        "\n",
        "    try:\n",
        "        # Identifica possíveis colunas de fornecedor e valor\n",
        "        colunas_fornecedor = [col for col in itens_df.columns if any(word in col.lower() for word in ['fornecedor', 'empresa', 'razao'])]\n",
        "        colunas_valor = [col for col in itens_df.columns if any(word in col.lower() for word in ['valor', 'preco', 'total'])]\n",
        "        colunas_quantidade = [col for col in itens_df.columns if any(word in col.lower() for word in ['qtd', 'quantidade', 'volume'])]\n",
        "        colunas_item = [col for col in itens_df.columns if any(word in col.lower() for word in ['item', 'produto', 'descricao'])]\n",
        "\n",
        "        if \"fornecedor\" in pergunta_lower and \"maior\" in pergunta_lower and \"montante\" in pergunta_lower:\n",
        "            if colunas_fornecedor and colunas_valor:\n",
        "                col_fornecedor = colunas_fornecedor[0]\n",
        "                col_valor = colunas_valor[0]\n",
        "\n",
        "                grupo = itens_df.groupby(col_fornecedor)[col_valor].sum()\n",
        "                fornecedor_maior = grupo.idxmax()\n",
        "                valor_maior = grupo.max()\n",
        "\n",
        "                return f\"Fornecedor com maior montante: {fornecedor_maior}\\nValor total: R$ {valor_maior:,.2f}\"\n",
        "\n",
        "        elif \"item\" in pergunta_lower and \"maior\" in pergunta_lower and \"volume\" in pergunta_lower:\n",
        "            if colunas_item and colunas_quantidade:\n",
        "                col_item = colunas_item[0]\n",
        "                col_qtd = colunas_quantidade[0]\n",
        "\n",
        "                grupo = itens_df.groupby(col_item)[col_qtd].sum()\n",
        "                item_maior = grupo.idxmax()\n",
        "                qtd_maior = grupo.max()\n",
        "\n",
        "                return f\"Item com maior volume: {item_maior}\\nQuantidade total: {qtd_maior}\"\n",
        "\n",
        "        elif \"total\" in pergunta_lower and \"notas\" in pergunta_lower:\n",
        "            return f\"Total de notas fiscais: {len(cabecalho_df)}\"\n",
        "\n",
        "        elif \"valor\" in pergunta_lower and \"total\" in pergunta_lower:\n",
        "            if colunas_valor:\n",
        "                col_valor = colunas_valor[0]\n",
        "                valor_total = itens_df[col_valor].sum()\n",
        "                return f\"Valor total de todas as notas: R$ {valor_total:,.2f}\"\n",
        "\n",
        "        else:\n",
        "            # Lista as colunas disponíveis para ajudar o usuário\n",
        "            return f\"\"\"\n",
        "            Não consegui entender sua pergunta.\n",
        "\n",
        "            Dados disponíveis:\n",
        "\n",
        "            CABEÇALHO ({len(cabecalho_df)} registros):\n",
        "            {', '.join(cabecalho_df.columns)}\n",
        "\n",
        "            ITENS ({len(itens_df)} registros):\n",
        "            {', '.join(itens_df.columns)}\n",
        "\n",
        "            Tente perguntas como:\n",
        "            - Qual fornecedor teve maior montante recebido?\n",
        "            - Qual item teve maior volume entregue?\n",
        "            - Quantas notas fiscais temos no total?\n",
        "            - Qual o valor total de todas as notas?\n",
        "            \"\"\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Erro ao processar a pergunta: {str(e)}\"\n",
        "\n",
        "# Lista de exemplos\n",
        "exemplos_perguntas = [\n",
        "    \"Qual o fornecedor que teve maior montante recebido?\",\n",
        "    \"Qual item teve maior volume entregue?\",\n",
        "    \"Quantas notas fiscais temos no total?\",\n",
        "    \"Qual o valor total de todas as notas fiscais?\",\n",
        "    \"Quais são os 5 maiores valores de itens?\"\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzVeibJZsO6L",
        "outputId": "2eb0e48b-8c6c-4c63-9c98-7eaa6c8f5f13"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados CSV carregados com sucesso.\n",
            "\n",
            "Cabeçalho - 100 registros\n",
            "Colunas: ['CHAVE DE ACESSO', 'MODELO', 'SÉRIE', 'NÚMERO', 'NATUREZA DA OPERAÇÃO', 'DATA EMISSÃO', 'EVENTO MAIS RECENTE', 'DATA/HORA EVENTO MAIS RECENTE', 'CPF/CNPJ Emitente', 'RAZÃO SOCIAL EMITENTE', 'INSCRIÇÃO ESTADUAL EMITENTE', 'UF EMITENTE', 'MUNICÍPIO EMITENTE', 'CNPJ DESTINATÁRIO', 'NOME DESTINATÁRIO', 'UF DESTINATÁRIO', 'INDICADOR IE DESTINATÁRIO', 'DESTINO DA OPERAÇÃO', 'CONSUMIDOR FINAL', 'PRESENÇA DO COMPRADOR', 'VALOR NOTA FISCAL']\n",
            "\n",
            "Itens - 565 registros\n",
            "Colunas: ['CHAVE DE ACESSO', 'MODELO', 'SÉRIE', 'NÚMERO', 'NATUREZA DA OPERAÇÃO', 'DATA EMISSÃO', 'CPF/CNPJ Emitente', 'RAZÃO SOCIAL EMITENTE', 'INSCRIÇÃO ESTADUAL EMITENTE', 'UF EMITENTE', 'MUNICÍPIO EMITENTE', 'CNPJ DESTINATÁRIO', 'NOME DESTINATÁRIO', 'UF DESTINATÁRIO', 'INDICADOR IE DESTINATÁRIO', 'DESTINO DA OPERAÇÃO', 'CONSUMIDOR FINAL', 'PRESENÇA DO COMPRADOR', 'NÚMERO PRODUTO', 'DESCRIÇÃO DO PRODUTO/SERVIÇO', 'CÓDIGO NCM/SH', 'NCM/SH (TIPO DE PRODUTO)', 'CFOP', 'QUANTIDADE', 'UNIDADE', 'VALOR UNITÁRIO', 'VALOR TOTAL']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação da interface Gradio\n",
        "import gradio as gr\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=perguntar_ao_agente,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Digite sua pergunta sobre os dados das Notas Fiscais aqui...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"GTIA - Pesquise nas NFs\",\n",
        "    description=(\n",
        "        \"Faça sua pergunta!\"\n",
        "    ),\n",
        "    live=False, # Não atualiza em tempo real enquanto o usuário digita\n",
        "    css=\"\"\"\n",
        "    body { font-family: 'Inter', sans-serif; background-color: #f0f2f5; }\n",
        "    .gradio-container { max-width: 800px; margin: 40px auto; border-radius: 15px; overflow: hidden; box-shadow: 0 10px 30px rgba(0,0,0,0.1); }\n",
        "    .gr-header { background-color: #4CAF50; color: white; padding: 20px; text-align: center; border-radius: 15px 15px 0 0; }\n",
        "    .gr-interface-panel { padding: 20px; }\n",
        "    .gr-textbox label { font-weight: bold; color: #333; }\n",
        "    .gr-textbox textarea { border-radius: 8px; border: 1px solid #ddd; padding: 10px; transition: all 0.3s ease; }\n",
        "    .gr-textbox textarea:focus { border-color: #4CAF50; box-shadow: 0 0 5px rgba(76, 175, 80, 0.5); outline: none; }\n",
        "    .gr-button { background-color: #007bff; color: white; border: none; border-radius: 8px; padding: 10px 20px; font-size: 16px; cursor: pointer; transition: background-color 0.3s ease, transform 0.2s ease; }\n",
        "    .gr-button:hover { background-color: #0056b3; transform: translateY(-2px); }\n",
        "    .gradio-output { background-color: #e9ecef; border-radius: 8px; padding: 15px; border: 1px solid #ced4da; margin-top: 20px; white-space: pre-wrap; word-wrap: break-word; }\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Lançamento da interface Gradio\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Iniciando a interface Gradio...\")\n",
        "    iface.launch(share=True) # share=True gera um link público temporário para compartilhar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "3MQS7lAwoz4O",
        "outputId": "0c5c9fc5-ff33-4586-fe53-74620108cf5f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando a interface Gradio...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a8e9050bdb6e9a588a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a8e9050bdb6e9a588a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}